{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "连接neo4j数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "#define the parameters, host, query and keywords\n",
    "uri = \"xxxxxx\"\n",
    "driver = GraphDatabase.driver(uri, auth=(\"neo4j\", \"xxxxxx\"))\n",
    "session = driver.session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neo4j查询函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(tx, query, cid, product, attribute,attribute_val):\n",
    "    result_list=[]\n",
    "    for record in tx.run(query, customerid=cid,productname=product, attribute=attribute,value=attribute_val):\n",
    "        result_list.append(record[0])\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义neo4j查询语句"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_q = (\"MATCH (c:Customer)-[r:HAS]->(p:Product) \" \n",
    "    \"WHERE c.customer_id = $customerid AND p.product_name = $productname \" \n",
    "    \"RETURN DISTINCT properties(r)\")\n",
    "\n",
    "check_c = (\"MATCH (c:Customer) \" \n",
    "    \"WHERE c.customer_id = $customerid \" \n",
    "    \"RETURN DISTINCT c\")\n",
    "\n",
    "update_q = (\"MATCH (c:Customer)-[r:HAS]->(p:Product) \" \n",
    "    \"WHERE c.customer_id = $customerid AND p.product_name = $productname \"\n",
    "    \"and r.TYPE = $attribute \"\n",
    "    \"SET r.VALUE = toInteger($value) \"\n",
    "    \"RETURN DISTINCT properties(r)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义意图字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_dict = {'check':check_q, 'login':check_c, 'update':update_q}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载Spacy NLP库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载自定义分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#list of key intent, product and attribute\n",
    "product_list = ['deposit','loan']\n",
    "attribute_list = ['pricing','balance']\n",
    "intent_list = ['check','update']\n",
    "\n",
    "tokens_products = nlp(' '.join(product for product in product_list))\n",
    "tokens_intent = nlp(' '.join(intent for intent in intent_list))\n",
    "tokens_attribute = nlp(' '.join(attribute for attribute in attribute_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "意图提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def intent_entity_attribute_extraction(nlp, sentence, tokens_intent, tokens_product, tokens_attribute):\n",
    "    #please implement your sentence classification here to extract the intent\n",
    "    tokens = nlp(sentence)\n",
    "    #use the NER to extract the entity regarding product\n",
    "\n",
    "    intent_score= 0\n",
    "    product_score = 0\n",
    "    attribute_score = 0\n",
    "    final_intent = ''\n",
    "    final_product = ''\n",
    "    final_attribute = ''\n",
    "    final_attribute_value = ''\n",
    "\n",
    "    threshold = 0.8\n",
    "\n",
    "    for token in tokens:\n",
    "        for intent in tokens_intent:\n",
    "            curr_intent_score = token.similarity(intent)\n",
    "            if curr_intent_score > intent_score and curr_intent_score > threshold:\n",
    "                intent_score = curr_intent_score\n",
    "                final_intent = intent.text\n",
    "\n",
    "        for product in tokens_product:\n",
    "            curr_product_score = token.similarity(product)\n",
    "            if curr_product_score > product_score and curr_product_score > threshold:\n",
    "                product_score = curr_product_score\n",
    "                final_product = product.text\n",
    "                    \n",
    "        for attribute in tokens_attribute:\n",
    "            curr_attribute_score = token.similarity(attribute)\n",
    "            if curr_attribute_score > attribute_score and curr_attribute_score > threshold:\n",
    "                attribute_score = curr_attribute_score\n",
    "                final_attribute = attribute.text\n",
    "\n",
    "        if token.pos_ == 'NUM' and token.text.isdigit():\n",
    "            final_attribute_value = token.text\n",
    "\n",
    "    print('matching...')\n",
    "    print(final_intent, final_product, final_attribute, final_attribute_value)\n",
    "    return (final_intent, final_product, final_attribute, final_attribute_value)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a63688bd6bac23ef02bd6d37e471970d737fd4f4530cb65b7bef3153fa56e0ea"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
